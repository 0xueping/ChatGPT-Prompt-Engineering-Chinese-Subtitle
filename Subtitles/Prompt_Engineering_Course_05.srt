1
00:00:00,000 --> 00:00:07,020
This next video is on inferring.
这个视频将讲述推断。

2
00:00:07,020 --> 00:00:09,480
I like to think of these tasks where the model takes
我喜欢把这些任务想象成模型接收

3
00:00:09,480 --> 00:00:12,100
a text as input and perform some kind of analysis.
文本作为输入并进行某种分析的任务。

4
00:00:12,100 --> 00:00:14,600
So this could be extracting labels,
因此，这可能包括提取标签、

5
00:00:14,600 --> 00:00:19,240
extracting names, kind of understanding the sentiment of a text, that kind of thing.
提取名称、理解文本的情感，等等。

6
00:00:19,240 --> 00:00:22,440
So if you want to extract a sentiment,
所以，如果您想提取情感，

7
00:00:22,440 --> 00:00:24,200
positive or negative of a piece of text,
正面或负面的文本，

8
00:00:24,200 --> 00:00:26,860
in the traditional machine learning workflow,
在传统的机器学习工作流中，

9
00:00:26,860 --> 00:00:29,660
you'd have to collect the label dataset,
您需要收集标签数据集，

10
00:00:29,660 --> 00:00:33,160
train a model, figure out how to deploy the model somewhere in the Cloud,
训练一个模型，找出如何将模型部署到云端，

11
00:00:33,160 --> 00:00:34,200
and make inferences.
并进行推断。

12
00:00:34,200 --> 00:00:35,280
That can work pretty well,
这种方法可以工作得很好，

13
00:00:35,280 --> 00:00:38,520
but it was just a lot of work to go through that process.
但是要这个过程，需要做很多工作。

14
00:00:38,520 --> 00:00:43,640
Also, for every task such as sentiment versus extracting names versus something else,
此外，对于每个任务，如情感分析、提取名称或其他任务，

15
00:00:43,640 --> 00:00:46,860
you have to train and deploy a separate model.
您需要训练并部署一个单独的模型。

16
00:00:46,860 --> 00:00:48,700
One of the really nice things about
大型语言模型的一个很好的特点是

17
00:00:48,700 --> 00:00:51,340
large language model is that for many tasks like these,
对于许多类似的任务，

18
00:00:51,340 --> 00:00:56,180
you can just write a prompt and have it start generating results pretty much right away.
您只需编写一个提示，它就可以立即开始生成结果。

19
00:00:56,180 --> 00:01:00,000
That gives tremendous speed in terms of application development.
这在应用程序开发方面带来了巨大的提速。

20
00:01:00,000 --> 00:01:02,280
You can also just use one model,
您也可以只使用一个模型、

21
00:01:02,280 --> 00:01:05,440
one API to do many different tasks rather than needing to
一个API来完成许多不同的任务，而不是需要

22
00:01:05,440 --> 00:01:09,120
figure out how to train and deploy a lot of different models.
弄清楚如何训练和部署许多不同的模型。

23
00:01:09,120 --> 00:01:13,720
So with that, let's jump into the code to see how you can take advantage of this.
有了这个，让我们跳到代码中，看看您如何利用这个优势。

24
00:01:13,720 --> 00:01:16,120
So here's our usual starter code.
这是我们通常的初始代码。

25
00:01:16,120 --> 00:01:19,120
I'll just run that.
我只需运行它。

26
00:01:19,120 --> 00:01:23,800
The most of the example I'm going to use is a review for a lamp.
我使用的最多的示例，是一个关于台灯的评论。

27
00:01:23,800 --> 00:01:26,860
So need a nice lamp for the bedroom,
卧室里需要一盏漂亮的灯，

28
00:01:26,860 --> 00:01:30,140
and this one additional storage, and so on.
以及额外的存储空间，等等。

29
00:01:30,140 --> 00:01:39,340
Let me write a prompt to classify the sentiment of this.
让我编写一个提示，来对此进行情感分类。

30
00:01:39,340 --> 00:01:44,500
If I want the system to tell me what is the sentiment,
如果我想让系统告诉我，这是什么情绪，

31
00:01:44,500 --> 00:01:51,220
I can just write what is
我可以直接写出

32
00:01:51,220 --> 00:02:01,240
the sentiment of the following product review with the usual delimiter,
"以下产品评论的情感是什么？"，加上通用的分隔符

33
00:02:01,240 --> 00:02:04,480
and the review text, and so on, and let's run that.
以及评论文本等等，然后运行它。

34
00:02:04,480 --> 00:02:08,840
This says the sentiment of the product review is positive,
这表明产品评论的情感是积极的，

35
00:02:08,840 --> 00:02:11,360
which actually seems pretty right.
这实际上看起来非常正确。

36
00:02:11,360 --> 00:02:12,800
This lamp isn't perfect,
这个灯并不完美，

37
00:02:12,800 --> 00:02:14,680
but this customer seems pretty happy.
但这位顾客似乎非常满意。

38
00:02:14,680 --> 00:02:17,000
Seems to be a great company that cares about the customers and products.
这似乎是一家关心客户和产品的优秀公司。

39
00:02:17,000 --> 00:02:20,340
I think positive sentiment seems to be the right answer.
我认为积极的情感似乎是正确的答案。

40
00:02:20,340 --> 00:02:22,360
Now, this prints out the entire sentence,
现在，这会打印出整个句子，

41
00:02:22,360 --> 00:02:25,440
the sentiment of the product review is positive.
产品评论的情感是积极的。

42
00:02:25,440 --> 00:02:31,640
If you wanted to give a more concise response to make it easier for post-processing,
如果您想给出更简洁的回应，以便于后期处理，

43
00:02:31,640 --> 00:02:35,080
I can take this prompt and add another instruction
我可以在这个提示中加入另一个指令

44
00:02:35,080 --> 00:02:37,240
to give you answers to single word,
给出一个单词作为答案，

45
00:02:37,240 --> 00:02:38,800
either positive or negative.
正面或负面。

46
00:02:38,800 --> 00:02:40,800
So it just prints out positive like this,
所以它只会打印出“正面”这样，

47
00:02:40,800 --> 00:02:43,040
which makes it easier for a piece of text to take
这使得接收文本变得更容易

48
00:02:43,040 --> 00:02:46,720
this output and process it and do something with it.
处理这个输出并对其执行某些操作。

49
00:02:46,720 --> 00:02:49,280
Let's look at another prompt.
让我们看另一个提示。

50
00:02:49,280 --> 00:02:52,100
Again, still using the lamp review.
再次使用灯具的评论。

51
00:02:52,100 --> 00:02:57,580
Here, I have it identify a list of emotions that the writer of the following review is
这里，我让它识别以下评论作者所表达的一系列情感，

52
00:02:57,580 --> 00:03:01,380
expressing including no more than five items in this list.
包括这个列表中不超过五个项目。

53
00:03:01,380 --> 00:03:04,640
So large language models are pretty good at
因此，大型语言模型非常擅长

54
00:03:04,640 --> 00:03:08,260
extracting specific things out of a piece of text.
从一段文本中提取特定内容。

55
00:03:08,260 --> 00:03:11,740
In this case, we're expressing the emotions.
在这种情况下，我们在表达情感。

56
00:03:11,740 --> 00:03:14,240
This could be useful for understanding
这对于理解

57
00:03:14,240 --> 00:03:18,260
how your customers think about a particular product.
您的客户如何看待某个特定产品可能是有用的。

58
00:03:18,260 --> 00:03:21,420
For a lot of customer support organizations,
对于很多客户支持机构来说，

59
00:03:21,420 --> 00:03:26,220
it's important to understand if a particular user is extremely upset.
了解某个特定用户是否非常不满是很重要的。

60
00:03:26,220 --> 00:03:30,340
So you might have a different classification problem like this,
所以您可能会遇到类似的分类问题，

61
00:03:30,340 --> 00:03:34,820
is the writer of the following review expressing anger because if someone is really angry,
判断以下评论的作者是否表达了愤怒，因为如果有人真的很生气，

62
00:03:34,820 --> 00:03:39,780
it might merit paying extra attention to have a customer review,
可能值得花费额外的关注来获得客户评价，

63
00:03:39,780 --> 00:03:41,860
to have customer support or customer success,
获得客户认可或成功拿下客户，

64
00:03:41,860 --> 00:03:45,960
reach out to figure what's going on and make things right for the customer.
主动联系，了解情况并为客户解决问题，

65
00:03:45,960 --> 00:03:48,880
In this case, the customer is not angry.
在这种情况下，客户并不生气。

66
00:03:48,880 --> 00:03:52,160
Notice that with supervised learning,
注意到，在监督学习中，

67
00:03:52,160 --> 00:03:55,340
if I had wanted to build all of these classifiers,
如果我想要构建所有这些分类器，

68
00:03:55,340 --> 00:03:58,800
there's no way I would have been able to do this with supervised learning
我不可能在短短几分钟内做到，如果是使用监督学习的话。

69
00:03:58,800 --> 00:04:04,000
in just a few minutes that you saw me do so in this video.
但就像您在这个视频中看到的那样，我只用了几分钟完成了任务。

70
00:04:04,000 --> 00:04:08,460
I'd encourage you to pause this video and try changing some of these prompts.
我鼓励您暂停这个视频，尝试修改一些提示。

71
00:04:08,460 --> 00:04:12,600
Maybe ask if the customer is expressing delight or ask if there are
也许询问客户是否表达了愉悦，或者询问是否有

72
00:04:12,600 --> 00:04:15,860
any missing parts and see if you can get a prompt to make
任何缺失的部分，看看您是否可以让提示做出

73
00:04:15,860 --> 00:04:20,100
different inferences about this lab review.
关于这个实验评论的不同推断。

74
00:04:20,100 --> 00:04:28,280
Let me show some more things that you can do with this system,
让我展示一些您可以用这个系统做的其他事情，

75
00:04:28,280 --> 00:04:34,820
specifically extracting richer information from a customer review.
特别是从客户评论中提取更丰富的信息。

76
00:04:34,820 --> 00:04:39,860
So information extraction is the part of NLP,
所以信息提取是自然语言处理（NLP）的一部分，

77
00:04:39,860 --> 00:04:43,100
of natural language processing that relates to taking a piece of
它与从一段

78
00:04:43,100 --> 00:04:47,980
text and extracting certain things that you want to know from the text.
文本中提取您想了解的特定内容相关。

79
00:04:47,980 --> 00:04:49,420
So in this prompt,
所以在这个提示中，

80
00:04:49,420 --> 00:04:52,780
I'm asking it, identify the following items,
我问它，识别以下项目，

81
00:04:52,780 --> 00:04:57,280
the item purchase and the name of the company that made the item.
“购买的商品”和“制造商名称”。

82
00:04:57,280 --> 00:05:00,080
Again, if you are trying to summarize
再者，如果您试图总结

83
00:05:00,080 --> 00:05:05,280
many reviews from an online shopping e-commerce website,
来自在线购物电商网站的许多评论，

84
00:05:05,280 --> 00:05:07,860
it might be useful for your large collection of reviews
这一点可能会很有用---

85
00:05:07,860 --> 00:05:10,120
to figure out what were the items,
搞清评论中涉及的物品是什么，

86
00:05:10,120 --> 00:05:11,480
who made the item,
制造商是谁，

87
00:05:11,480 --> 00:05:14,860
figure out positive and negative sentiment to track trends about
找出正面和负面情感，以跟踪关于

88
00:05:14,860 --> 00:05:20,420
positive or negative sentiment for specific items or for specific manufacturers.
特定物品或特定制造商的正面或负面情感趋势。

89
00:05:20,420 --> 00:05:24,900
In this example, I'm going to ask it to format your response as
在这个例子中，我要求它将您的回答格式化为

90
00:05:24,900 --> 00:05:29,380
a JSON object with item and brand as the keys.
具有 item 和 brand 作为关键字的 JSON 对象。

91
00:05:29,380 --> 00:05:31,860
So if I do that,
所以如果我这样做，

92
00:05:31,860 --> 00:05:33,780
it says the item is a lamp,
它说物品是一盏灯，

93
00:05:33,780 --> 00:05:35,840
the brand is Luminar,
品牌是Luminar，

94
00:05:35,840 --> 00:05:37,940
and you can easily load this into
您可以很容易地将此加载到

95
00:05:37,940 --> 00:05:42,820
Python dictionary to then do additional processing on this output.
Python字典中，然后对此输出进行额外处理。

96
00:05:42,820 --> 00:05:44,540
In the examples we've gone through,
在我们所看过的例子中，

97
00:05:44,540 --> 00:05:48,580
you saw how to write a prompt to recognize the sentiment,
您看到了如何编写一个用于识别情感的提示，

98
00:05:48,580 --> 00:05:50,940
figure out if someone is angry,
弄清楚是否有人生气，

99
00:05:50,940 --> 00:05:54,660
and then also extract the item and the brand.
然后还提取物品和品牌。

100
00:05:54,660 --> 00:05:59,940
One way to extract all of this information would be to use
提取所有这些信息的一种方法是使用

101
00:05:59,940 --> 00:06:05,020
three or four prompts and call get_completion,
三个或四个提示并调用get_completion，

102
00:06:05,020 --> 00:06:06,360
three times or four times,
三次或四次，

103
00:06:06,360 --> 00:06:09,920
extract these different views one at a time.
一次提取这些不同的视角。

104
00:06:09,920 --> 00:06:13,040
But it turns out you can actually write a single prompt
但事实证明，您实际上可以编写一个单一的提示

105
00:06:13,040 --> 00:06:16,000
to extract all of this information at the same time.
来同时提取所有这些信息。

106
00:06:16,000 --> 00:06:18,920
So let's say identify the fine items,
那么，让我们识别这些精选项目，

107
00:06:18,920 --> 00:06:23,000
extract sentiment, is reviewer expressing anger,
提取情感，评论者是否表达了愤怒，

108
00:06:23,000 --> 00:06:25,800
item purchase, company that made it.
购买项目，制造公司。

109
00:06:25,800 --> 00:06:33,440
Then here, I'm also going to tell it to format the anger value as a Boolean value.
在这里，我还会告诉它将愤怒值格式化为布尔值。

110
00:06:33,440 --> 00:06:35,900
Let me run that.
让我运行一下。

111
00:06:35,900 --> 00:06:43,420
This outputs a JSON where sentiment is positive,
这将输出一个情感为积极的JSON，

112
00:06:43,420 --> 00:06:45,820
anger, and then no quotes around false
愤怒，然后没有引号包围false

113
00:06:45,820 --> 00:06:48,780
because it also just output it as a Boolean value.
因为它也只是将其输出为布尔值。

114
00:06:48,780 --> 00:06:52,460
Extracted the item as lamp with additional storage instead of lamp.
提取的物品是带额外存储的灯，而不是灯。

115
00:06:52,460 --> 00:06:55,140
Seems okay. But this way,
看起来还不错。但这样，

116
00:06:55,140 --> 00:07:02,380
you can extract multiple fields out of a piece of text with just a single prompt.
您可以使用一个提示从一段文本中提取多个字段。

117
00:07:02,380 --> 00:07:05,160
As usual, please feel free to pause the video
像往常一样，请随时暂停视频

118
00:07:05,160 --> 00:07:08,120
and play with different variations on this yourself.
尝试一下，看看有什么不同变化。

119
00:07:08,120 --> 00:07:11,680
Or maybe even try typing in a totally different review to
或者甚至尝试输入一个完全不同的评论来

120
00:07:11,680 --> 00:07:15,440
see if you can still extract these things accurately.
看看您是否仍然可以准确提取这些内容。

121
00:07:15,440 --> 00:07:19,400
Now, one of the cool applications I've seen of
现在，我见过的大型语言模型的一个很酷的应用是

122
00:07:19,400 --> 00:07:22,520
large language models is inferring topics.
推断主题。

123
00:07:22,520 --> 00:07:24,960
Given a long piece of text,
给定一段较长的文本，

124
00:07:24,960 --> 00:07:29,400
what is this piece of text about? What are the topics?
这段文本是关于什么的？有哪些主题？

125
00:07:29,400 --> 00:07:33,300
Here's a fictitious newspaper article about how
这里有一篇虚构的报纸文章，讲述的是

126
00:07:33,300 --> 00:07:37,660
government workers feel about the agency they work for.
政府工作人员对他们所在机构的看法。

127
00:07:37,660 --> 00:07:41,340
The recent survey conducted by government and so on,
最近政府进行的一项调查等等，

128
00:07:41,340 --> 00:07:43,100
results reviewed at NASA was
在NASA进行的结果审查是

129
00:07:43,100 --> 00:07:46,300
a popular department with high satisfaction rating.
一个拥有高满意度评级的热门部门。

130
00:07:46,300 --> 00:07:47,900
I am a fan of NASA,
我是NASA的粉丝，

131
00:07:47,900 --> 00:07:50,980
I love the work they do, but this is a fictitious article.
我喜欢他们所做的工作，但这是一篇虚构的文章。

132
00:07:50,980 --> 00:07:53,220
Given an article like this,
对于这样一篇文章，

133
00:07:53,220 --> 00:07:57,820
we can ask it with this prompt,
我们可以用这个提示来提问，

134
00:07:57,820 --> 00:08:03,260
determine five topics that are being discussed in the following text.
确定以下文本中正在讨论的五个主题。

135
00:08:03,260 --> 00:08:05,720
Let's make each item one or two words long,
让我们将每个项目设为一到两个单词长度，

136
00:08:05,720 --> 00:08:09,220
for my response in a comma separated list.
将我的回答用逗号分隔的列表表示。

137
00:08:09,220 --> 00:08:11,100
If we run that,
如果我们运行这个，

138
00:08:11,100 --> 00:08:14,600
we get out this article is about a government survey,
我们得到这篇文章是关于政府调查的，

139
00:08:14,600 --> 00:08:17,760
is about job satisfaction, is about NASA, and so on.
关于工作满意度、关于NASA等等。

140
00:08:17,760 --> 00:08:23,280
Overall, I think pretty nice extraction of a list of topics.
总的来说，我认为这是一个很好的主题列表提取。

141
00:08:23,280 --> 00:08:27,200
Of course, you can also split it so you
当然，您也可以将其拆分，

142
00:08:27,200 --> 00:08:34,320
get a Python list with the five topics that this article was about.
得到一个包含这篇文章涉及的五个主题的Python列表。

143
00:08:34,320 --> 00:08:38,540
If you have a collection of articles and extract topics,
如果您有一系列文章并提取主题，

144
00:08:38,540 --> 00:08:40,760
you can then also use
然后您还可以使用

145
00:08:40,760 --> 00:08:45,600
a large language model to help you index into different topics.
大型语言模型帮助您对不同主题进行索引。

146
00:08:45,600 --> 00:08:48,500
Let me use a slightly different topic list.
让我使用一个略有不同的主题列表。

147
00:08:48,500 --> 00:08:52,200
Let's say that we're a news website or something,
假设我们是一个新闻网站或类似的，

148
00:08:52,200 --> 00:08:54,680
and these are the topics we track.
这些是我们关注的主题。

149
00:08:54,680 --> 00:08:57,780
NASA, local government, engineering, employee satisfaction,
NASA、地方政府、工程、员工满意度，

150
00:08:57,780 --> 00:09:01,600
federal government, and let's say you want to figure out,
联邦政府，假设您想要找出，

151
00:09:01,600 --> 00:09:03,200
given a news article,
给定一篇新闻文章，

152
00:09:03,200 --> 00:09:07,680
which of these topics are covered in that news article.
这些主题中的哪些被该新闻文章涵盖了。

153
00:09:07,680 --> 00:09:10,700
Here's a prompt that I can use.
这是一个我可以使用的提示。

154
00:09:10,700 --> 00:09:13,680
I'm going to say, determine whether each item in
我将说，判断以下主题列表中的每个项目是否在下面的文本中是一个主题。

155
00:09:13,680 --> 00:09:16,800
the following list of topics is a topic in the text below.
给出一个由0和1组成的列表表示每个主题是否在文本中。

156
00:09:16,800 --> 00:09:20,760
Give your answer as a list of 01 for each topic.
将您的答案作为一个由0和1组成的列表，表示每个主题。

157
00:09:22,240 --> 00:09:25,760
Great. This is the same story text as before.
很好。这与之前的故事文本相同。

158
00:09:25,760 --> 00:09:28,160
This thing is a story. It is about NASA.
这是一个故事。它是关于NASA的。

159
00:09:28,160 --> 00:09:30,780
It's not about local governments, not about engineering.
它与地方政府和工程无关。

160
00:09:30,780 --> 00:09:35,040
It is about employee satisfaction and it is about federal government.
它是关于员工满意度和联邦政府的。

161
00:09:35,040 --> 00:09:37,640
With this, in machine learning,
有了这个，在机器学习中，

162
00:09:37,640 --> 00:09:42,240
this is sometimes called a zero-shot learning algorithm
这有时被称为零样本学习算法，

163
00:09:42,240 --> 00:09:45,520
because we didn't give it any training data that was labeled.
因为我们没有给它任何标记的训练数据。

164
00:09:45,520 --> 00:09:47,400
That's zero-shot.
这就是零样本。

165
00:09:47,400 --> 00:09:48,880
With just a prompt,
仅凭一个提示，

166
00:09:48,880 --> 00:09:55,800
it was able to determine which of these topics are covered in that news article.
它能够判断出哪些主题包含在那篇新闻文章中。

167
00:09:55,800 --> 00:10:00,680
If you want to generate a news alert,
如果您想生成一个新闻提醒，

168
00:10:00,680 --> 00:10:02,640
so that process news,
以便处理新闻，

169
00:10:02,640 --> 00:10:05,760
and I really like a lot of work that NASA does.
而且我真的很喜欢NASA所做的很多工作。

170
00:10:05,760 --> 00:10:10,480
If you want to build a system that can take this,
如果您想构建一个可以利用这个的系统，

171
00:10:10,480 --> 00:10:15,080
put this information into a dictionary and whenever NASA news pops up,
将这些信息放入字典中，每当有关NASA的新闻出现时，

172
00:10:15,080 --> 00:10:16,880
print alert, new NASA story.
打印提醒，新的NASA故事。

173
00:10:16,880 --> 00:10:20,440
They can use this to very quickly take any article,
他们可以使用这个方法迅速处理任何文章，

174
00:10:20,440 --> 00:10:22,600
figure out what topics it is about,
找出它涉及的主题，

175
00:10:22,600 --> 00:10:24,520
and if the topic includes NASA,
如果主题包括NASA，

176
00:10:24,520 --> 00:10:27,840
have it print out alert, new NASA story.
让它打印出提醒，新的NASA故事。

177
00:10:27,840 --> 00:10:32,400
Just one thing, I use this topic dictionary down here.
只是有一点，我在这里使用了这个主题字典。

178
00:10:32,400 --> 00:10:36,120
This prompt that I use up here isn't very robust.
我在这里使用的这个提示并不是很健壮。

179
00:10:36,120 --> 00:10:38,000
If I wanted a production system,
如果我想要一个生产系统，

180
00:10:38,000 --> 00:10:43,640
I would probably have it output the answer in JSON format,
我可能会让它以JSON格式输出答案，

181
00:10:43,640 --> 00:10:46,320
rather than as a list because the output
而不是作为一个列表，因为输出

182
00:10:46,320 --> 00:10:49,600
of the large language model can be a little bit inconsistent.
大型语言模型的输出可能会有些不一致。

183
00:10:49,600 --> 00:10:52,160
This is actually a pretty brittle piece of code.
这实际上是一段相当脆弱的代码。

184
00:10:52,160 --> 00:10:54,760
But if you want, when you're done watching this video,
但是如果您愿意，在观看完这个视频之后，

185
00:10:54,760 --> 00:10:58,720
feel free to see if you can figure out how to modify this prompt to have
请随意尝试看看您是否能弄明白如何修改这个提示以便让它

186
00:10:58,720 --> 00:11:01,960
an output JSON instead of a list like this and then have
输出JSON而不是像这样的列表，然后具备

187
00:11:01,960 --> 00:11:07,960
a more robust way to tell if a particular article is a story about NASA.
一种更稳健的方法来判断一篇特定文章是否关于NASA的故事。

188
00:11:07,960 --> 00:11:10,760
That's it for inferring.
这就是关于推理的部分。

189
00:11:10,760 --> 00:11:12,520
In just a few minutes,
仅仅几分钟，

190
00:11:12,520 --> 00:11:18,120
you can build multiple systems for making inferences about texts that previously
您可以构建多个用于对之前的文本进行推理的系统，

191
00:11:18,120 --> 00:11:23,680
just would have taken days or even weeks for a skilled machine learning developer.
而这对于一位熟练的机器学习开发者来说可能需要花费数天甚至数周的时间。

192
00:11:23,680 --> 00:11:28,600
I find this very exciting that both for skilled machine learning developers,
我觉得这对于熟练的机器学习开发者和

193
00:11:28,600 --> 00:11:31,680
as well as for people that are newer to machine learning,
对于刚接触机器学习的人来说都非常令人兴奋，

194
00:11:31,680 --> 00:11:37,400
you can now use prompting to very quickly build and start making
现在您可以使用提示非常快速地构建并开始进行

195
00:11:37,400 --> 00:11:42,840
inferences on pretty complicated natural language processing tasks like these.
像这些相当复杂的自然语言处理

196
00:11:42,840 --> 00:11:44,200
In the next video,
在下一个视频中，

197
00:11:44,200 --> 00:11:47,440
we'll continue to talk about exciting things you could do with
我们将继续讨论使用大型语言模型可以做的令人激动的事情，

198
00:11:47,440 --> 00:11:51,200
large language models and we'll go on to transforming.
并且我们将探讨“转换”。

199
00:11:51,200 --> 00:11:54,720
How can you take one piece of text and transform it into
如何将一段文本转换为

200
00:11:54,720 --> 00:11:58,400
a different piece of text such as translated to a different language.
不同的文本，例如翻译成另一种语言。

201
00:11:58,400 --> 00:12:01,240
Let's go on to the next video.
让我们继续观看下一个视频。
