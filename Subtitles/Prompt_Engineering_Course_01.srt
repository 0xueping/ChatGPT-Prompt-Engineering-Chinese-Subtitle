1
00:00:03,000 --> 00:00:09,000
Welcome to this course on ChatGPT Prompt Engineering for Developers.
欢迎学习这门《面向开发者的ChatGPT提示工程》课程。

2
00:00:09,000 --> 00:00:14,000
I'm thrilled to have with me, Isa Fulford, to teach this along with me.
我很高兴能邀请到Isa Fulford和我一起来教授这门课。

3
00:00:14,000 --> 00:00:20,900
She is a member of the technical staff of OpenAI and had built the popular ChatGPT retrieval plugin
她是OpenAI技术团队的一员，之前开发了备受欢迎的ChatGPT检索插件。

4
00:00:20,900 --> 00:00:27,000
and a large part of her work has been teaching people how to use LLM or large language model technology in products.
她的工作很大一部分是教人们如何在产品中使用LLM或大型语言模型技术。

5
00:00:27,000 --> 00:00:31,000
She's also contributed to the OpenAI cookbook that teaches people prompting.
她还为OpenAI手册做出了贡献，指导人们如何进行提示。
6
00:00:31,000 --> 00:00:33,000
So thrilled to have you with you.
非常高兴和你一起来授课。

7
00:00:33,000 --> 00:00:38,000
And I'm thrilled to be here and share some prompting best practices with you all.
我也很高兴来到这里，和大家分享一些提示工程的最佳实践。

8
00:00:38,000 --> 00:00:45,000
So there's been a lot of material on the Internet for prompting with articles like 30 prompts everyone has to know.
互联网上有很多关于提示工程的资料，比如“每个人都必须了解的30个提示”。

9
00:00:45,000 --> 00:00:54,000
A lot of that has been focused on the ChatGPT web user interface, which many people are using to do specific and often one-off tasks.
很多内容都集中在ChatGPT的Web界面上，许多人用它来完成特定的、通常是一次性的任务。

10
00:00:54,000 --> 00:01:00,000
But I think the power of LLM's large language models as a developer too,
但我认为，对于开发者而言，LLM大型语言模型的强大力量在于

11
00:01:00,000 --> 00:01:05,000
that is using API calls to LLMs to quickly build software applications,
使用API调用大语言模型来快速构建软件应用的能力。

12
00:01:05,000 --> 00:01:08,000
I think that is still very underappreciated.
我认为这一点仍然被严重低估。

13
00:01:08,000 --> 00:01:12,000
In fact, my team at AIFund, which is a sister company to Deep Learning.AI,
实际上，我的团队在AI Fund工作，这是Deep Learning.AI的一个姐妹公司，

14
00:01:12,000 --> 00:01:18,000
has been working with many startups on applying these technologies to many different applications.
一直在与许多初创公司合作，将这些技术应用到许多不同的应用场景。

15
00:01:18,000 --> 00:01:25,000
And it's been exciting to see what LLM APIs can enable developers to very quickly build.
看到LLM API能让开发者迅速构建的成果令人非常兴奋。

16
00:01:25,000 --> 00:01:29,400
So in this course, we'll share with you some of the possibilities
所以，在这门课程中，我们将与你分享一些可能性，

17
00:01:29,400 --> 00:01:34,000
for what you can do as well as best practices for how you can do them.
你能做什么以及你如何实现它们的最佳实践。

18
00:01:34,000 --> 00:01:36,000
There's a lot of material to cover.
内容很多啊

19
00:01:36,000 --> 00:01:41,000
First, you'll learn some prompting best practices for software development.
首先，你将学习一些用于软件开发的提示的最佳实践。

20
00:01:41,000 --> 00:01:47,140
Then we'll cover some common use cases, summarizing, inferring, transforming, expanding,
接下来我们将介绍一些常见的用例，如总结、推断、转换、扩展，

21
00:01:47,140 --> 00:01:50,000
and then you'll build a chatbot using an LLM.
然后你将使用LLM构建一个聊天机器人。

22
00:01:50,000 --> 00:01:55,000
We hope that this will spark your imagination about new applications that you can build.
我们希望这将激发你，关于可以构建新应用程序的想象力。

23
00:01:55,000 --> 00:01:58,000
So in the development of large language models or LLMs,
因此，在大型语言模型或LLM的开发过程中，

24
00:01:58,000 --> 00:02:06,000
there have been broadly two types of LLMs, which I'm going to refer to as base LLMs and instruction-tuned LLMs.
大致上有两种类型的LLM，我将它们称为基础型LLM和指令调整型LLM。

25
00:02:06,000 --> 00:02:11,000
So base LLM has been trained to predict the next word based on text training data,
基础型LLM经过训练，可以根据文本训练数据预测下一个单词，

26
00:02:11,000 --> 00:02:15,000
often trained on a large amount of data from the internet and other sources
通常在来自互联网和其他来源的大量数据上进行训练

27
00:02:15,000 --> 00:02:19,000
to figure out what's the next most likely word to follow.
用来找出接下来最可能出现的单词。

28
00:02:19,000 --> 00:02:24,000
So for example, if you were to prompt this, once upon a time there was a unicorn,
例如，如果你提示是，“从前有一个独角兽”，

29
00:02:24,000 --> 00:02:28,000
it may complete this, that is, it may predict the next several words are
它可能会这样来完成回答，也就是说，它可能会预测接下来的几个单词是：

30
00:02:28,000 --> 00:02:31,000
that live in a magical forest with all unicorn friends.
“和所有独角兽朋友一起生活在一个神奇的森林里”。

31
00:02:31,000 --> 00:02:35,000
But if you were to prompt this with what is the capital of France,
但是，如果你用“法国的首都是什么？”来提问，

32
00:02:35,000 --> 00:02:40,000
then based on what articles on the internet might have,
那么根据互联网上的文章可能有的内容，

33
00:02:40,000 --> 00:02:44,000
it's quite possible that the base LLM will complete this with
基础型LLM很可能会这样完成这个问题，比如：

34
00:02:44,000 --> 00:02:48,000
what is France's largest city, what is France's population, and so on,
（它会回答）法国最大的城市是什么、法国的人口是多少等等，

35
00:02:48,000 --> 00:02:52,000
because articles on the internet could quite plausibly be lists of
因为互联网上的文章可能就是关于

36
00:02:52,000 --> 00:02:55,000
quiz questions about the country of France.
法国这个国家的一系列问题。

37
00:02:55,000 --> 00:03:04,000
In contrast, an instruction-tuned LLM, which is where a lot of momentum of LLM research and practice has been going,
相反，指令调整型LLM是LLM研究和实践的发展方向，

38
00:03:04,000 --> 00:03:08,000
an instruction-tuned LLM has been trained to follow instructions.
指令调整型LLM已经被训练来遵循指令。

39
00:03:08,000 --> 00:03:11,000
So if you were to ask it, what is the capital of France,
所以如果你问它，“法国的首都是什么？”，

40
00:03:11,000 --> 00:03:16,000
it's much more likely to output something like the capital of France is Paris.
它更有可能输出类似于“法国的首都是巴黎”这样的答案。

41
00:03:16,000 --> 00:03:20,000
The way that instruction-tuned LLMs are typically trained is
指令调整型LLM通常的训练方法是，

42
00:03:20,000 --> 00:03:24,000
you start off with a base LLM that's been trained on a huge amount of text data
你首先从一个已经通过大量文本数据进行训练过的基础型LLM上开始，

43
00:03:24,000 --> 00:03:28,000
and further train it, further fine-tune it with inputs and outputs that are instructions and good attempts to follow those instructions,
并通过输入和输出对其进行进一步训练，进一步微调，

44
00:03:28,000 --> 00:03:32,000
that are instructions and good attempts to follow those instructions,
这些输入和输出都是指令以及遵循那些指令的良好尝试

45
00:03:32,000 --> 00:03:36,000
and then often further refine using a technique called RLHF,
然后通常会使用一种叫做RLHF的技术进一步优化，

46
00:03:36,000 --> 00:03:38,500
reinforcement learning from human feedback,
RLHF代表“从人类反馈中进行强化学习”，

47
00:03:38,500 --> 00:03:43,000
to make the system better able to be helpful and follow instructions.
使系统更能提供帮助并遵循指令。

48
00:03:43,000 --> 00:03:46,160
Because instruction-tuned LLMs have been trained
因为指令调整型LLMs已经被训练得

49
00:03:46,160 --> 00:03:48,800
to be helpful, honest, and harmless,
更有益、诚实和无害，

50
00:03:48,800 --> 00:03:54,983
so for example, they're less likely to output problematic text, such as toxic outputs, compared to base LLM,
举例来说，与基础型LLM相比，它们输出问题文本（如有毒输出）的可能性较小，

51
00:03:55,000 --> 00:04:01,000
a lot of the practical usage scenarios have been shifting toward instruction-tuned LLMs.
许多实际使用场景已经转向了指令调整型LLMs。

52
00:04:01,000 --> 00:04:06,200
Some of the best practices you find on the internet may be more suited for a base LLM,
你在互联网上找到的一些最佳实践可能更适合基础型LLM，

53
00:04:06,200 --> 00:04:08,000
but for most practical applications today,
但对于如今大多数实际应用，

54
00:04:08,000 --> 00:04:13,500
we would recommend most people instead focus on instruction-tuned LLMs,
我们建议大多数人转而关注经过指导微调的LLMs，

55
00:04:13,500 --> 00:04:15,000
which are easier to use and also,
这些LLM更易于使用

56
00:04:15,000 --> 00:04:22,000
because of the work of OpenAI and other LLM companies, becoming safer and more aligned.
因为OpenAI和其他LLM公司的努力，LLM变得越来越安全、一致。

57
00:04:22,000 --> 00:04:27,000
So this course will focus on best practices for instruction-tuned LLMs,
所以本课程将关注指令调整型LLMs的最佳实践，

58
00:04:27,000 --> 00:04:32,000
which is what we recommend you use for most of your applications.
这也是我们建议你在大多数应用中使用指令调整型LLMs的原因。

59
00:04:32,000 --> 00:04:36,000
Before moving on, I just want to acknowledge the team from OpenAI
在继续后面内容之前，我想借此感谢OpenAI团队

60
00:04:36,000 --> 00:04:39,000
and DeepLearning.ai that had contributed to the materials
以及DeepLearning.ai为这些教材做出贡献的人员

61
00:04:39,000 --> 00:04:42,000
that Isa and I will be presenting.
也就是我和Isa即将展示的这些课程材料。

62
00:04:42,000 --> 00:04:45,000
I'm very grateful to Andrew Mayne、Joe Palermo、Boris Power，
我非常感激来自OpenAI的Andrew Mayne、Joe Palermo、Boris Power，

63
00:04:45,000 --> 00:04:50,000
Ted Sanders， and Lilian Weng from OpenAI that were very involved with us
Ted Sanders和Lilian Weng，他们积极与我们合作

64
00:04:50,000 --> 00:04:53,000
brainstorming materials, vetting the materials to put together
一起头脑风暴讨论教材、审核教材，

65
00:04:53,000 --> 00:04:55,000
the curriculum for this short course.
为这门短期课程制定课程大纲。

66
00:04:55,000 --> 00:04:58,000
And I'm also grateful on the DeepLearning side for the work
同时我也感谢DeepLearning方面的工作，

67
00:04:58,000 --> 00:05:01,000
of Geoff Ladwig, Eddy Shyu, and Tommy Nelson.
包括Geoff Ladwig、Eddy Shyu和Tommy Nelson的贡献。

68
00:05:01,000 --> 00:05:06,000
So when you use an instruction-tuned LLM, think of giving instructions
当你使用指令调整型LLM时，请想象你在给另一个人下达指令，

69
00:05:06,000 --> 00:05:10,000
to another person, say someone that's smart but doesn't know
比如说，聪明但不了解

70
00:05:10,000 --> 00:05:12,000
the specifics of your task.
你任务具体内容的人。

71
00:05:12,000 --> 00:05:16,000
So when an LLM doesn't work, sometimes it's because the instructions
所以，当LLM不起作用时，有时是因为指令

72
00:05:16,000 --> 00:05:18,000
weren't clear enough.
不够清晰。

73
00:05:18,000 --> 00:05:21,000
For example, if you were to say, "Please write me something
例如，如果你说：“请给我写点关于

74
00:05:21,000 --> 00:05:25,000
about Alan Turing," well, in addition to that, it can be helpful to be clear
艾伦·图灵的事，"那么，除此之外，明确以下内容会有所帮助

75
00:05:25,000 --> 00:05:30,000
about whether you want the text to focus on his scientific work
你希望文本聚焦于他的科学工作，

76
00:05:30,000 --> 00:05:34,000
or his personal life or his role in history or something else.
还是他的个人生活、历史地位或是其他方面。

77
00:05:34,000 --> 00:05:39,000
And if you specify what you want the tone of the text to be,
如果你明确了希望文本的语调，

78
00:05:39,000 --> 00:05:43,000
should it take on the tone like a professional journalist would write,
是像专业记者那样的语调，

79
00:05:43,000 --> 00:05:46,000
or is it more of a casual note that you dash off to a friend?
还是更像是给朋友随意写的便条？

80
00:05:46,000 --> 00:05:49,000
That helps the LLM generate what you want.
这有助于LLM生成你想要的内容。

81
00:05:49,000 --> 00:05:52,000
And of course, if you picture yourself asking, say,
当然，如果你设想问下自己，比如说，

82
00:05:52,000 --> 00:05:56,000
a fresh college graduate to carry out this task for you,
（你让）一个刚毕业的大学生为你完成这个任务，

83
00:05:56,000 --> 00:05:59,000
if you can even specify what snippets of text they should read
如果你能明确他们应该阅读哪些文本段落，

84
00:05:59,000 --> 00:06:02,000
in advance to write this text about Alan Turing,
以便提前撰写关于艾伦·图灵的文字，

85
00:06:02,000 --> 00:06:06,000
then that even better sets up that fresh college grad for success
那么这将更好地帮助那位刚毕业的大学生成功地

86
00:06:06,000 --> 00:06:09,000
to carry out this task for you.
为你完成这个任务。

87
00:06:09,000 --> 00:06:14,000
So in the next video, you see examples of how to be clear and specific,
下一个视频中，你将会看到如何清晰、明确地描述提示的示例，

88
00:06:14,000 --> 00:06:17,000
which is an important principle of prompting LLMs,
这是LLM提示工程的一个重要原则，

89
00:06:17,000 --> 00:06:21,000
and you also learn from Isa a second principle of prompting,
同时你还将从Isa那里学到提示工程的第二个重要原则，

90
00:06:21,000 --> 00:06:24,000
that is giving the LLM time to think.
那就是给予LLM一些思考的时间。

91
00:06:24,000 --> 00:06:27,000
So with that, let's go on to the next video.
那么现在，让我们继续观看下一个视频。
